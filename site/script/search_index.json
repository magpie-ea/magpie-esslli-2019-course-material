[
["index.html", "Primer on replication, preregistration and open science through browser-based experiments in _magpie Chapter 1 About this book", " Primer on replication, preregistration and open science through browser-based experiments in _magpie Michael Franke Last compiled: 2019-08-13 Chapter 1 About this book Experimental work is hard. Opportunities for suboptimality and failure abound. This course is all about avoiding pitfalls and cultivating a mindset aimed at continually improving practices. We will execute the whole process of implementation, execution and data analysis during this course, based on a replication of an existing experiment, which we will preregister. We do this using _magpie, an architecture to help realize browser-based experiments. This is the material for a course taught at ESSLLI 2019 (Riga, Latvia). "],
["empirical-research.html", "Chapter 2 Potential problems with empirical science 2.1 Objective evidence 2.2 Observation vs. manipulation 2.3 The publication-generating process 2.4 Researcher degrees of freedom", " Chapter 2 Potential problems with empirical science Let’s look at some fictitious case studies (science fiction if you wish). We will use them to remind ourselves of the benefits of experimental methods and of the perils of naivety about their limitations. 2.1 Objective evidence Smith has talked to a lot of people during the last 10 years and made extensive notes. He claims that using the right toothpaste makes you smarter. Smith knows this because he talked to a lot of people and made extensive notes. Q: Why do we not believe him? 2.2 Observation vs. manipulation Smith subjected 700 people to an IQ test. He also recorded for each participant which toothpaste they use regularly. (There are only two brands: bling and shiny.) Here’s a visualization of his data: Figure 2.1: Distribution of IQ-scores for different brands of toothpaste! A statistical test reveals that there is a significant difference between the two groups of toothpaste users. Smith publishes a paper with the title: ``shiny makes you smart.’’ Q: Why do you strongly dislike this paper? 2.3 The publication-generating process Smith recruited 50 participants. Each used one brand of toothpaste for 4 weeks before taking an IQ test. A statistical test reveals that there is significant difference between the two groups. Smith submits a research paper with the title ``You are what you brush: shiny makes you smart.’’ to a top-tier journal. Meanwhile, another researcher, Jones, has independently carried out the same experiment. A statistical test on Jones’ data reveals no significant difference between groups. Jones still submits a research paper to a top-tier journal with the title ``Expect the expected: toothpaste does not influence IQ scores.’’ Three months later, Smith’s paper gets published, Jones’ doesn’t. Q: Do you think that something like this could happen in reality? If so, why would this be disturbing? 2.4 Researcher degrees of freedom Jones is frustrated by the rejection. She looks at her data again. She realizes that toothpaste does have a significant effect on IQ scores after all, but only for right-handed participants and the subset of IQ-questions related to language. She also realizes that this ties in with Prof. Brainstawn’s work on lateralization. She submits a paper to a different journal. The paper is accepted as: ``Brush up your language the right way: toothpaste influences on IQ and lateralization in the brain.’’ Q: Why is this bad for science? "],
["countermeasures.html", "Chapter 3 Countermeasures 3.1 Direct replication 3.2 Preregistration 3.3 Open Science", " Chapter 3 Countermeasures Nothing will ever completely rule out the possibility that honest researchers make mistakes, or that fraudulent researchers cheat. But there are possibilities to make it harder to cheat, easier to detect cheating and, most importantly, to create awareness of the pitfalls of bad research practices, so that the majority of honest researchers is prevented from accumulating false knowledge based on honest mistakes. Three powerful methods for raising awareness and minimizing the harmful effects of bad scientific practices are: direct replication, preregistration and open science. 3.1 Direct replication No matter how carefully done, we can never be certain that a research finding is true. This is inherent in the nature of a chance event. Collecting empirical data is observing the outcome of a chance event. Every once in a while, we will, by stochastic necessity, observe something quite extraordinary. Every once in a while, the extraordinary observation nicely supports a beautiful, but false, theory. A false research finding is the result. But if we repeat the experiment that led to the extraordinary observation, chances are that the new experimental data will not be extraordinary (regression to the mean). Chances are that it does not support the beautiful, but false theory. This is why a society of careful scientists will wish to maximally scrutinize every important research result by direct replication. Direct replication tries to recreate the exact conditions C from a previous experiment believed necessary for effect X and tests whether X is observed in a new experiment which implements C. Direct replication contrasts with conceptual replication. Conceptual replication examines predictions of a general idea which was previously tested in one scenario in a different setting. Conceptual replication is much more wide-spread, it is important to our knowledge gain, and it, too, helps to a certain extent avoid long-term belief in false theory. But to rule out accidental false positives, or other pitfalls of dubious empirical research, direct replication is key. Unfortunately, conducting direct replications is much less conducive of building a reputation as a world-class scientist. Direct replications explore no novel territory, and they either produce “what we already knew” (but did we really?) or come accross as a destructive force of an aggressive methodological elite. Two obvious ways forward are these. Firstly, society can change its evaluation of direct replication. This is already starting to happen, with research funds dedicated to (direct) replication studies. Secondly, direct replication can be a key ingredient of science education. Just like every new generation of careful thinkers must heavily doubt and scrutinize the theoretical constructs delivered to them by the past, so should they pick up their role as a “clean-up squad” in the data-domain. When the goal is acquisition of skills in the implementation and execution of an experimental study, a direct replication takes away the burden to come up with an interesting research question and a clever design. Moreover, when young students read an experimental paper with the goal of direct replication, they will probably have a completely new reading experience: the level of critical depth and inquisitiveness necessary for direct replication far exceeds how we would normally just skim the Methods &amp; Results sections to get to the Discussion as soon as possible. 3.2 Preregistration It is an old idea that, in order to reduce researcher degrees of freedom1, empirical studies should be preregistered. A strict way of preregistering a study, is in the form of so-called peer-reviewed registered reports, where researchers submit a detailed plan for their study before data collection and analysis to a journal. The plan is peer-reviewed and judged. When accepted, researchers carry out the data collection, perform the analysis, write the whole paper, which is then (almost) automatically accepted, no matter whether the data shows the theoretically anticipated effects or not. Since, unfortunately, not many journals accept peer-reviewed registered reports, a less strict, but still very useful form of preregistration works as follows. Before data collection, researchers write a preregistration report, post it publically (for example on the platform of the open science foundation), and then refer to this public pre-commitment in the final paper. The preregistration report is as detailed as possible. The more researcher degrees of freedom are eliminated, the better. It should include: concise theoretical background the research hypotheses to be tested the experimental design if possible, upload also all material and the experiment itself details about data collection participant pool, number of participants to recruit, … data preprocessing exclusion criteria, replacement criteria, methods of aggregation, … data analysis ideally, upload a script with the exact analysis you plan to conduct If a preregistration report does not rule out all researcher degrees of freedom (how could it?), it is still better than no preregistration report at all. 3.3 Open Science Science is a collaborative enterprise. No single mind suffices to do all of the work. This is not an exercise in outsmarting others. It’s an exercise in collective accumulation of knowledge. Mistakes occur, and we need others to spot the errors made. This requires openness, ideally as early as during peer-review. Openness entails making available: (anonymized) raw data ideally: with explanation of what it all means scripts for data processing and the processed data ideally: well commented scripts for data analysis ideally: well commented the experimental material, possibly the experiment code itself There can always be good reasons why sharing is not possible (for a while). Sensitive data or copyright come to mind. Still, as with preregistration, as much as can be shared should be shared in the interest of transparency and maximal error control. The term “researcher degrees of freedom” refers to the extent to which researchers are at liberty to make decisions that may seem innocuous enough, but that may alter the overall qualitative conclusions. These decisions may often be justifiable. Consider: “Ah, but surely we should exclude this guy’s data from analysis because it shows clear weirdnesses in the plot, and this guy also behaved very strangely during the lab session, I seem to recall.” Or: “If I analyze the data from the Likert rating scale task as ordinal, nothing is significant; but if I treat is as metric, I get more interpretable results.”↩ "],
["version-control-with-git.html", "Chapter 4 Version control with git 4.1 A plea for tidiness during collaboration 4.2 Minimal git 4.3 Learning by doing", " Chapter 4 Version control with git 4.1 A plea for tidiness during collaboration Experimental work is usually done in a team. When you work with others (and this usually includes past and future versions of yourself) it is good practice to be tidy. You want to be able to access the latest version of your work immediately. You want to be able to work in parallel, without corrupting your teammates’ work. When conflicts arise, you want to solve them easily. What you should not do, at least if you want to work with me, is send files per email, or have a shared Dropbox folder that looks like this (“aktuelle_version” means “current version”): A tidy folder structure instead could look like this: Ideally, you document (if only for your future self) which folder contains what, e.g., using a light-weight language like markdown. 4.2 Minimal git On top of a clean, and well documented folder structure, using a version control system is an excellent idea to boost efficient cooperation (once more: including cooperation with your future self). A currently very popular instance of VC is git. There are many great introductions to git, text-based and videos. Have your pick! There are GUIs and Apps for your smartphone. That’s impressive, but I recommend using the command line, or built-in functions in your favorite text editor. The most important thing you need to know about git for this course, is that git keeps a remote copy and as many local copies as you want of the complete history of your project, called repository. When you make changes locally during your work, you first tell your local repository that these changes are to stay for good: you “commit to them”. When you start working you first “synchronize” your local copy of the repository with the remote, by “pulling” the latest changes to your own machine. For this course, we will really only need the basic commands: git clone :: to “download” a local copy of an online repository, if you do not already have one git pull :: to “update” your local copy, e.g., after others have made changes git add :: to stage changes or files for the next commit git commit :: to, well, commit yourself to the currently staged changes git push :: to “upload” your changes, so others can pull them The basic workflow and its main concepts are summarized here: 4.3 Learning by doing Here’s an extended git exercise that visits the most basic, and some more advanced features of git. Try to carry it out step by step on your own. 4.3.1 Working with a local repository 4.3.1.1 Creating a repository open a command line tool create a folder of your choice e.g., mkdir my_first_git 4.3.1.2 Adding a file go to this directory and initialize e.g., cd my_first_git &amp;&amp; git init add a file called mynotes.md to the directory open the file with a text editor type some markdown &amp; save the file make sure to write several lines inspect the status with git status add the file to version control with git add mynotes.md inspect the status with git status again now commit your changes with git commit -m &quot;my first commit&quot; inspect the status with git status again look at the log history of your repo with git log 4.3.1.3 Add another file create another file called mynotes_2.md fill in some content of your choice add it to version control using the same procedure as before 4.3.1.4 Seeing current changes make some edits to mynotes.md add text in some lines delete some text in existing lines inspect the status with git status this tells you which files changed, but not how exactly type git diff mynotes.md to see changes between last commit &amp; current version commit these changes type git diff mynotes.md again 4.3.1.5 Seeing changes between commits you can see what changed in all files from COMMIT-1 to COMMIT-2 by typing git diff mynotes.md COMMIT-1 COMMIT-2 here COMMIT-x is the commit ID (which you find in the output of git log) zoom in on changes in file mynotes.md with git diff mynotes.md COMMIT-1 COMMIT-2 -- mynotes.md type git log -p mynotes.md to get a full change history of file mynotes.md 4.3.1.6 Undoing staging make changes to your file mynotes.md stage the changes with git add mynotes.md look at git status (boring!) to unstage these changes type git reset mynotes.md look at git status again check whether your changes got lost (using what you learned above) 4.3.1.7 Undoing local changes 4.3.1.7.1 Single files type git checkout mynotes.md to undo your recent local changes check the status and the diff between local file and last commit 4.3.1.7.2 Whole repo change both of your files &amp; inspect the status type git reset --hard to undo all local changes inspect status to verify 4.3.1.8 Going back in time retrieve the (shortened) commit ID of your first commit by git log --oneline type git checkout FIRST-COMMIT-ID to roll back complete to where you were in the beginning 4.3.1.9 Branching so far our history of developments was linear; it’s time to change that create a new branch with git branch silly_try switch to that new branch with git checkout silly_try add one or more lines with text at the beginning (!) of mynotes.md don’t change anything else in the file! add &amp; commit the changes with git commit -a -m &quot;changes to a branch&quot; look at your history now with git log --graph --oneline --all we now live in a branching-time universe different developments of your project live next to each other 4.3.1.10 Merging we will now parallel universes together switch back to the master branch with git checkout master merge the changes into the master branch with git merge silly_try if we are lucky git will merge automatically if not, there will be so-called merge conflicts if you have merge conflicts, you will need to resolve them manually commit your changes with git commit -a -m &quot;merged in branch silly_try&quot; have a look at your history with git log --graph --oneline --all 4.3.1.11 Resolving merge conflicts when a conflict occurs and git cannot merge automatically, it creates a new file in which both changes are kept side by side the user must then decide by hand which changes to keep or how to merge use will find tools of your taste for doing this by searching the internet 4.3.2 Working with a remote repository 4.3.2.1 Creating and linking the remote repository create a remote repository, e.g., on GitHub link your local repo to the global one with git remote add origin YOUR-REPO-URL now origin is the name for your remote repo 4.3.2.2 Pushing and pulling pushing is when you “upload” local changes pulling is when you “download” remote changes merge conflicts can arise just like when merging branches "],
["basics-of-magpie.html", "Chapter 5 Basics of _magpie 5.1 Basic concepts and architecture 5.2 A first example", " Chapter 5 Basics of _magpie 5.1 Basic concepts and architecture The basic concepts and architecture of _magpie is covered in the _magpie quick start guide. 5.2 A first example We will reimplement an online version of a questionaire study reported by Hoekstra et al. in a paper from 2014 that appeared in the Psychonomic Bulletin &amp; Review under the title “Robust misinterpretation of confidence intervals.” (Hoekstra et al. 2014). The questionaire was a single paper page that looked like this: The questionare used by Hoekstra et al (2014). 5.2.1 Getting started clone the “departure point” repository using git clone https://github.com/magpie-ea/magpie-departure-point rename the folder to a more fitting name and move to it download the required _magpie packages npm install update the information in the file README.md download this catchy photograph by professor Bumbledorf in action and place it in the images folder open the file 04_trials.js and replace the previous object trial_info with the following: const trial_info = { forced_choice: [ { question: &quot;Is the following statement a valid conclusion to draw from Prof. Bumbledorf&#39;s result, given the definition of a &#39;confidence interval&#39;?&quot;, QUD: &quot;Professor Bumbledorf conducts an experiment, analyzes the data, and reports:&quot;, picture: &quot;images/Prof-Bumbledorf.png&quot;, option1: &#39;yes&#39;, option2: &#39;no&#39;, correct: &#39;no&#39; } ] }; now, try out the experiment by opening the file index.html in the browser 5.2.2 Adding more content We now need to add the statements to be judged from the original paper, reproduced below: “The probability that the true mean is greater than 0 is at least 95%.”, “The probability that the true mean equals 0 is smaller than 5%.”, “The “null hypothesis” that the true mean equals 0 is likely to be incorrect.&quot;, “There is a 95 % probability that the true mean lies between 0.1 and 0.4.”, “We can be 95 % confident that the true mean lies between 0.1 and 0.4.”, “If we were to repeat the experiment over and over, then 95 % of the time the true mean falls between 0.1 and 0.4.” The problem is: where / how should we add these statements with the simple template that we are using? Ideally they should appear between the question and the repsonse buttons. Ideally, the statements should be highlighted, e.g., in bold. Can you think of a creative solution? (Hint: you can include HTML code in the strings given to fields like question etc.) The solution is in this footnote.2 Finally, also add an item number to each trial, i.e., consecutively number each question by inserting, for example item: 1 for the first question, item: 2 for the second, etc. 5.2.3 Adding another view The original paper also asked participants to rate their own statistical expertise on a scale from 1 (“no stats course taken”) to 10 (“teaching statistics at a university”). Let’s also add such a view before the questions about “confidence intervals” (because when not being able to answer the questions, participants might downgrade their self-assessed statistics expertise). We will use the template view for rating scales, which gives us a rating scale from 1 to 7, but that’s enough for our purposes here. open the file 05_views.js look at the documentation of the rating scale view and copy-paste the following code (at the end of the file): const statistical_expertise_rating = magpieViews.view_generator(&quot;rating_scale&quot;, { trials: 1, name: &#39;expertise_rating&#39;, data: [{ question: &quot;Please indicate your level of statistical experience from 1 (no stats course taken, no practical experience), to 7 (teaching statistics at a university)?&quot;, optionLeft: &#39;&#39;, optionRight: &#39;&#39; }] }); open the file 06_main.js and add the view in the right place in the view sequence, i.e., change it to: views_seq: [ intro, instructions, statistical_expertise_rating, forced_choice_2A, post_test, thanks, ] 5.2.4 More advanced customizing The rating scale view includes a lot of white space for a picture, but we do not have a picture right now. We can customize each view. See the docs for more information on customization. Here’s an example: change to view specification in 05_views.js to the following: const statistical_expertise_rating = magpieViews.view_generator(&quot;rating_scale&quot;, { trials: 1, name: &#39;expertise_rating&#39;, data: [{ question: &quot;Please indicate your level of statistical experience from 1 (no stats course taken, no practical experience), to 7 (teaching statistics at a university)?&quot;, optionLeft: &#39;&#39;, optionRight: &#39;&#39; }] }, { stimulus_container_generator: function(config, CT) { return `&lt;div class=&#39;magpie-view&#39;&gt; &lt;h1 class=&#39;magpie-view-title&#39;&gt;${config.title}&lt;/h1&gt; &lt;p class=&#39;magpie-view-question magpie-view-qud&#39;&gt;${config.data[CT].QUD}&lt;/p&gt; &lt;/div&gt;`; } }); 5.2.5 Finishing the job Though the basic functionality is there, the experiment is not polished yet. Add an appropriate welcoming message instructions, and a begin view between the expertise rating and the yes/no questions. A complete example of this experiment can also be found here. References "],
["case-study-on-acceptability-of-indicative-conditionals.html", "Chapter 6 Case study on acceptability of indicative conditionals 6.1 Theoretical background 6.2 “The Adams family” 6.3 Replication of Douven and Verbrugge (2010)", " Chapter 6 Case study on acceptability of indicative conditionals 6.1 Theoretical background Adams famously proposed that the assertability of a conditional sentence \\(P \\rightarrow Q\\) is given by the conditional probability \\(P(Q \\mid P)\\) on some probability distribution representing the uncertainty of the speaker or of the interlocutors’ combined (Adams 1975). Jackson (1987) proposed a reformulation, namely that the acceptability of a conditional \\(P \\rightarrow Q\\) is given by the conditional probability \\(P(Q \\mid P)\\). We call this idea Adams’ thesis (AT). 6.2 “The Adams family” 6.2.1 Design &amp; Materials Douven and Verbrugge (2010) seek to test Adams’ thesis experimentally. Towards this end, they present participants with 30 vignettes, each containing a context and a conditional statement. Here is one example: Context: All students in class 6C have at least a B for their math test paper. Statement: If Ben is in class 6C, then he has at least a B for his math test paper. They then measured, in a between-subjects manipulation spread across three different experiments, how participants rate the statements according to four different kinds of questions, targeted at measuring different theoretical constructs: Acceptability: Participants were asked: “How acceptable is this statement in the given context?” Reasonable belief: Participants were asked: “How reasonable is it to believe this statement in the given context?” Probability of truth of conditional: Participants were asked: “How probable is it that this statement is true in the given context?” The fourth measure, had a slightly different shape: Conditional probability: The context included additionally the clause “Suppose that \\(P\\) is true.” and the statement to be rated was just the consequent \\(Q\\). Participants were then asked: “How acceptable is this statement in the given context?” Of the 30 vignettes, a triplet of 10 vignettes each instantiated one of three types of conditional sentences, namely deductive, inductive and abductive conditionals. 6.2.2 Hypotheses &amp; statistical analyses Adams’ thesis is interpreted as a statement about the measures of “acceptability” and “conditional probability”. Douven &amp; Verbrugge consider a sequence of ever milder variations on AT, namely: AT-strong: \\(Ac(P \\rightarrow Q) = P(Q \\mid P)\\) AT-approximate: \\(Ac(P \\rightarrow Q) \\approx P(Q \\mid P)\\) AT-categorical: \\(Ac(P \\rightarrow Q)\\) is high/middling/low iff \\(P(Q \\mid P)\\) is high/middling/low AT-correlation-strong: \\(Ac(P \\rightarrow Q)\\) highly correlates with \\(P(Q \\mid P)\\) AT-correlation-weak: \\(Ac(P \\rightarrow Q)\\) at least moderately correlates with \\(P(Q \\mid P)\\) We will focus in the following on AT-approximate and AT-correlation-weak . Moreover, Douven &amp; Verbrugge hypothesize that, according to AT, we would not expect any differences between different types of conditionals. In sum, we have two main hypotheses, each with a subordinate hypothesis, which the paper addresses as follows with statistical tests: H1 :: AT-approximate: There is no difference between ratings given for the “acceptability” and those given for the “conditional probability” condition. The paper tests this in the form of a main effect of GROUP in an ANOVA with factors GROUP (which question was answered) and COND-TYPE (which type of conditional sentence was rated). H1-types: Since AT predicts no differences between types of conditionals, there should be no main effect of COND-TYPE or an interaction between GROUP and COND-TYPE. H2 :: AT-correlation-weak: There is a positive correlation between average ratings for the “acceptability” ratings and the “conditional probability” ratings (two averaged measures for each of the 30 vignettes, compared against each other). The paper addresses this by a correlation test. H2-types: Since AT predicts no differences between types of conditionals, there should be no difference in correlation tests when we look at each type of conditional in isolation. 6.2.3 Results Douven and Verbrugge (2010) report data that discredits Adams’ thesis, at least under strong and encompassing interpretations. As for H1 and H1-types, they report a main effect of GROUP (rating “acceptability” vs rating “conditional probability”), a significant main effect of COND-TYPE and a significant interaction between the two (their Experiment 1). This result is visually discernible in the plot below, taken from Douven and Verbrugge (2010), where data from ratings of “probability of truth of conditional” (see above) are also plotted. Douven and Verbrugge (2010) also report a significant correlation, in general support of H2, but note that H2-types is cast into doubt because the interaction on the data with only inductive conditions is, though significant, less pronounced (\\(R = .65\\), compared to \\(R = .81\\) and \\(R = .88\\) for abductive and deductive conditionals respectively). 6.3 Replication of Douven and Verbrugge (2010) The following is an example preregistration report, a version of which is also available online References "],
["deployment-of-magpie-experiments.html", "Chapter 7 Deployment of _magpie experiments", " Chapter 7 Deployment of _magpie experiments Refer to _magpie site. "],
["advanced-features-of-magpie.html", "Chapter 8 Advanced features of _magpie", " Chapter 8 Advanced features of _magpie life cycles &amp; hooks custom views "],
["references.html", "Chapter 9 References", " Chapter 9 References "],
["references-1.html", "References", " References "]
]
